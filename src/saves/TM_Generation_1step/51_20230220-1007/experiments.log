[58]2023-02-20 10:07:53,377: 
>>>>> Main Config
[Dataset]
data_dir: data
dataset: chall/DIAL_MWP-Dataset/dataset
testsets: ['test10', 'test90', 'test_time']
add_kor_number: False
add_figure_number: True
use_ixc: True
use_iec: True
use_isc: True

[Evaluator]


[EarlyStop]
early_stop: 30
early_stop_measure: test10_accuracy
pos_improve: True

[Experiment]
num_epochs: 500
verbose: 0
print_step: 1
test_step: 3
test_from: 0
save_step: 50
model_name: TM_Generation_1step
seed: 0
gpu: 1

>>>>> model Config
[Model]
batch_size: 32
test_batch_size: 128
lr: 3e-05
reg: 0
beam_size: 1
decoder_lr: -1
bert_max_len: 384
decoder_num_layers: 3
decoder_num_heads: 8
demo: False
pretrained_path: monologg/koelectra-base-v3-discriminator
model_weight_path: None
lr_schedule: False
warmup_rate: 0.1
mp_enabled: True
accumulation_steps: 2
max_grad_norm: 5.0
swa_warmup: 4
decode_only_input_token: True
use_category: False
do_mask_imq: False
imq_mask_ratio: 0.1


[58]2023-02-20 10:07:53,378: 
Dataset: chall/DIAL_MWP-Dataset/dataset

[58]2023-02-20 10:08:01,655: train start ... !
[58]2023-02-20 10:11:20,344: epoch=  1, loss=13431.513, train time=198.69, epoch time=198.69 (198.69 + 0.00)
[58]2023-02-20 10:14:36,060: epoch=  2, loss=4333.271, train time=195.72, epoch time=195.72 (195.72 + 0.00)
[58]2023-02-20 10:19:42,730: epoch=  3, loss=3170.074, train time=200.34, epoch time=306.67 (200.34 + 106.32), valid_loss=0.0000, valid_accuracy=0.0515, valid_num_error=15.0000, valid_error_rate=0.0067, train_loss=8407036.0000, test10_loss=0.0000, test10_accuracy=0.0413, test10_num_error=0.0000, test10_error_rate=0.0000, test90_loss=0.0000, test90_accuracy=0.0502, test90_num_error=7.0000, test90_error_rate=0.0064, test_time_loss=0.0000, test_time_accuracy=0.0250, test_time_num_error=0.0000, test_time_error_rate=0.0000
[58]2023-02-20 10:24:41,397: epoch=  4, loss=4588.232, train time=298.67, epoch time=298.67 (298.67 + 0.00)
[58]2023-02-20 10:28:00,301: epoch=  5, loss=5718.553, train time=198.90, epoch time=198.90 (198.90 + 0.00)
